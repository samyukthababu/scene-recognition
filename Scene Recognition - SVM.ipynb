{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8b5685c7",
      "metadata": {
        "id": "8b5685c7"
      },
      "source": [
        "# **1. Loading the Training dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e57a59",
      "metadata": {
        "id": "63e57a59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "import math\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552aeb85",
      "metadata": {
        "id": "552aeb85"
      },
      "outputs": [],
      "source": [
        "path = \"training\"\n",
        "width = 256\n",
        "height = 256\n",
        "dimension = (width, height)\n",
        "encoding = 0\n",
        "label = []\n",
        "data = []\n",
        "encoded_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1926a08b",
      "metadata": {
        "id": "1926a08b"
      },
      "outputs": [],
      "source": [
        "for root, directory, files in os.walk(path):\n",
        "\n",
        "    # example of the root drive/MyDrive/training/bedroom\n",
        "    if root != path:\n",
        "        counter = 0\n",
        "        for fp in files:\n",
        "            if fp != \".DS_Store\":\n",
        "                counter += 1\n",
        "\n",
        "                # example of the filepath drive/MyDrive/training/bedroom/0.jpg\n",
        "                filepath = os.path.join(root, fp)\n",
        "\n",
        "                # Images are of different shapes\n",
        "                img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # All images have the dimension (256, 256) => (width, height)\n",
        "                img = cv2.resize(img_array, dimension)\n",
        "                data.append(img)\n",
        "                encoded_labels.append(encoding)\n",
        "\n",
        "        encoding += 1\n",
        "        # Getting the label\n",
        "        label.append(root.split(\"/\")[-1])\n",
        "\n",
        "label = list(set(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9ae2bb6",
      "metadata": {
        "id": "b9ae2bb6",
        "outputId": "fb713f1d-d5c0-4e55-9446-77410071e573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1500, 256, 256)\n",
            "(1500,)\n"
          ]
        }
      ],
      "source": [
        "# X contains all 1500 images\n",
        "# Shape = 1500, 256, 256\n",
        "X = np.array(data)\n",
        "print(X.shape)\n",
        "\n",
        "# y contains the labels of X\n",
        "# Shape = 1500,\n",
        "y = np.array(encoded_labels)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe538bf7",
      "metadata": {
        "id": "fe538bf7"
      },
      "source": [
        "# 2. Spliting the Data as Training set and Validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e02c38",
      "metadata": {
        "id": "e8e02c38"
      },
      "outputs": [],
      "source": [
        "# 90% for the Training set and 10% for the Validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)\n",
        "\n",
        "# Shape of X_train = (1350, 256, 256)\n",
        "# Shape of y_train = (1350,)\n",
        "# Shape of X_val = (150, 256, 256)\n",
        "# Shape of y_val = (150,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bc13e7",
      "metadata": {
        "id": "c9bc13e7"
      },
      "source": [
        "# 3. Using only the Training set to create the Vocabulary:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85dde64",
      "metadata": {
        "id": "f85dde64"
      },
      "source": [
        "## **3.1. Visual Feature extraction using Dense SIFT:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddcf482",
      "metadata": {
        "id": "3ddcf482"
      },
      "outputs": [],
      "source": [
        "def sift_features(X):\n",
        "\n",
        "    # Dense SIFT with different number of key points.\n",
        "    # The whole idea of dense SIFT is to have key points over the entire image, having more irrelevant information as well\n",
        "    # Since the image size is choosen as 256x256, we can choose say step_size = 4 or 8\n",
        "    step_size = 8\n",
        "    key_points = []\n",
        "    dense_descriptors = []\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    counter = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        counter += 1\n",
        "        temp = []\n",
        "        for m in range(0, len(X[0]), step_size):\n",
        "            for n in range(0, len(X[1]), step_size):\n",
        "                temp.append(cv2.KeyPoint(m, n, step_size))\n",
        "\n",
        "        # List of key-points for each image\n",
        "        key_points_image = tuple(temp)\n",
        "\n",
        "        # Each image has 1024 key points\n",
        "        key_points.append(key_points_image)\n",
        "\n",
        "        _, dense_features =  sift.compute(X[i], temp)\n",
        "\n",
        "        # There are 1024 key points in each image\n",
        "        # That means there will be 128 feature descriptor for each of those 1024 key points\n",
        "        # Thus the shape will be (1024, 128) for each of the dense features\n",
        "        # There are a total of 1500 images, which means the dense_descriptor\n",
        "        # will have a shape of (1500, 1024, 128)\n",
        "        dense_descriptors.append(dense_features)\n",
        "\n",
        "    return key_points, dense_descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6803e823",
      "metadata": {
        "id": "6803e823"
      },
      "outputs": [],
      "source": [
        "key_points_train, dense_descriptors_train = sift_features(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6c39a0",
      "metadata": {
        "id": "3e6c39a0",
        "outputId": "8e743475-82be-4bb3-902a-afad33d2a2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1350\n",
            "<class 'list'>\n",
            "1024\n",
            "<class 'tuple'>\n",
            "\n",
            "\n",
            "1350\n",
            "<class 'list'>\n",
            "(1024, 128)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Key points\n",
        "print(len(key_points_train))\n",
        "print(type(key_points_train))\n",
        "print(len(key_points_train[0]))\n",
        "print(type(key_points_train[0]))\n",
        "print()\n",
        "print()\n",
        "\n",
        "# Descriptors\n",
        "print(len(dense_descriptors_train))\n",
        "print(type(dense_descriptors_train))\n",
        "print(dense_descriptors_train[0].shape)\n",
        "print(type(dense_descriptors_train[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66876bd8",
      "metadata": {
        "id": "66876bd8"
      },
      "source": [
        "## **3.2. Creating the Bag of Visual Words (BoVW) or the Vocabulary:**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dab2767",
      "metadata": {
        "id": "8dab2767"
      },
      "source": [
        "### 3.2.1. Creating all the Descriptors for the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d9f69a",
      "metadata": {
        "id": "a9d9f69a"
      },
      "outputs": [],
      "source": [
        "def all_descriptors(dense_descriptors):\n",
        "    list_of_descriptor = []\n",
        "\n",
        "    for image_descriptor in dense_descriptors:\n",
        "        for feature_vector in image_descriptor:\n",
        "            list_of_descriptor.append(feature_vector)\n",
        "\n",
        "    return list_of_descriptor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e921ed",
      "metadata": {
        "id": "d5e921ed"
      },
      "outputs": [],
      "source": [
        "list_of_descriptor_train = all_descriptors(dense_descriptors_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b75b9ffa",
      "metadata": {
        "id": "b75b9ffa",
        "outputId": "5ba06754-1685-4a8e-be3c-38d705866f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1382400\n",
            "<class 'list'>\n",
            "\n",
            "128\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(len(list_of_descriptor_train))\n",
        "print(type(list_of_descriptor_train))\n",
        "print()\n",
        "\n",
        "print(len(list_of_descriptor_train[0]))\n",
        "print(type(list_of_descriptor_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24cbe8ce",
      "metadata": {
        "id": "24cbe8ce",
        "outputId": "bc524757-1884-40ca-ba5c-a3f7d9de98e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   1.,   1.,   1.,   0.,   0.,   0.,   0.,   2.,  10.,\n",
            "         6.,   2.,   0.,   0.,   0.,   2.,   2.,   5.,   3.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         1.,  21.,   5.,   1.,   0.,   0.,   0.,   0.,   8., 147.,  38.,\n",
            "         5.,   0.,   0.,   1.,   4.,  15., 108.,  23.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   4.,  32.,   1.,   0.,  10.,\n",
            "       167.,   7.,   5.,  35., 106.,  30.,   7., 151., 226.,  56.,   3.,\n",
            "        37.,  46.,  12.,  17., 226., 226.,  24.], dtype=float32), array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "         0.,   0.,   5.,   3.,   1.,   0.,   0.,   0.,   0.,   4.,  45.,\n",
            "        19.,   4.,   0.,   0.,   1.,   4.,   6.,  37.,  11.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,  12.,   0.,   0.,\n",
            "         2.,  79.,   3.,   2.,  13.,  39.,  12.,   3.,  57., 177.,  31.,\n",
            "         1.,  12.,  14.,   3.,   5., 127., 177.,  17.,   0.,   0.,   0.,\n",
            "         0.,   0.,   0.,   0.,   0.,   1.,   8.,  40.,   3.,   1.,  26.,\n",
            "        88.,   5.,   7.,  49., 142.,  40.,  14., 162., 177.,  45.,  14.,\n",
            "        50.,  64.,  27.,  35., 177., 177.,  22.], dtype=float32)]\n",
            "(1382400, 128)\n"
          ]
        }
      ],
      "source": [
        "# Since these are separate np.array's, we can convert them into a single array using numpy\n",
        "print(list_of_descriptor_train[0:2])\n",
        "\n",
        "# The shape of the output is (1350*1024, 128)\n",
        "# This is becasue when we are training on the k-means clustering algorithm, we only care about the feature vectors\n",
        "# The information regarding which image they come from is not needed\n",
        "list_of_descriptor_train = np.stack(list_of_descriptor_train)\n",
        "print(list_of_descriptor_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad369532",
      "metadata": {
        "id": "ad369532"
      },
      "source": [
        "### 3.2.2. Using k-means to find the Vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7018f41",
      "metadata": {
        "id": "c7018f41"
      },
      "outputs": [],
      "source": [
        "# K-means clustering is now performed and similar BoVW are grouped together\n",
        "# Then the centre of those clusters are returned\n",
        "\n",
        "k_means = KMeans(n_clusters = 200, random_state = 0, n_init = 1, verbose = 0)\n",
        "k_means.fit(list_of_descriptor_train)\n",
        "vocabulary = k_means.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc41d078",
      "metadata": {
        "id": "cc41d078",
        "outputId": "aa692ce6-004d-459e-d83c-b79ccd8261e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "<class 'numpy.ndarray'>\n",
            "(200, 128)\n"
          ]
        }
      ],
      "source": [
        "# This is our vocabulary for the training data\n",
        "print(len(vocabulary))\n",
        "print(type(vocabulary))\n",
        "print(vocabulary.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b21df93b",
      "metadata": {
        "id": "b21df93b"
      },
      "source": [
        "### 3.2.3. Creating a mapping between cluster centroids (vocabulary) and the descriptors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971df0d5",
      "metadata": {
        "id": "971df0d5"
      },
      "outputs": [],
      "source": [
        "def mapping(dense_descriptors):\n",
        "    # Map the images to the appropriate vocabulary\n",
        "    # This means we will now be storing the images as histograms and no longer as images\n",
        "    visual_words = []\n",
        "\n",
        "    for image_descriptors in dense_descriptors:\n",
        "        map_to_vocab = []\n",
        "        for descriptor in image_descriptors:\n",
        "\n",
        "            # Eucledian Distance between these descriptors and vocabulary\n",
        "            # Shape of the descriptor is (200, 128)\n",
        "            descriptor_stack = np.tile(descriptor, (200, 1))\n",
        "\n",
        "            # Shape is (200, 128)\n",
        "            difference = descriptor_stack - vocabulary\n",
        "\n",
        "            # This will have the euclidean distance between each descriptor (128,) and the visual word (200, 128)\n",
        "            e_dist = pow(((pow(difference, 2)).sum(axis = 1)), 0.5)\n",
        "\n",
        "            # Finding the index of the minimum distance and this is the cluster index that it belongs to\n",
        "            temp = list(e_dist)\n",
        "            index_of_vocab = temp.index(min(temp))\n",
        "\n",
        "            # For the specific descriptor, this will be the cluster that it maps to\n",
        "            map_to_vocab.append(index_of_vocab)\n",
        "        map_to_vocab = np.array(map_to_vocab)\n",
        "        visual_words.append(map_to_vocab)\n",
        "    return visual_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e59bff",
      "metadata": {
        "id": "54e59bff"
      },
      "outputs": [],
      "source": [
        "visual_words = mapping(dense_descriptors_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3da9ff7",
      "metadata": {
        "id": "c3da9ff7",
        "outputId": "d9468ad8-7529-41a5-846c-26dccf74b8d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1350\n",
            "<class 'list'>\n",
            "\n",
            "1024\n",
            "<class 'numpy.ndarray'>\n",
            "[136 101  22 ...  95  95  95]\n"
          ]
        }
      ],
      "source": [
        "# The variable visual_words represents the mapping to the vocabulary\n",
        "print(len(visual_words))\n",
        "print(type(visual_words))\n",
        "print()\n",
        "\n",
        "print(len(visual_words[0]))\n",
        "print(type(visual_words[0]))\n",
        "print(visual_words[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2da258b",
      "metadata": {
        "id": "f2da258b"
      },
      "source": [
        "### 3.2.4. Counting the vocabulary in the image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1270fa2",
      "metadata": {
        "id": "e1270fa2"
      },
      "outputs": [],
      "source": [
        "def histogram(visual_words):\n",
        "    # Converting all the images into histograms that represents\n",
        "    # the count of the number of times that a specific vocabulary appeared in the image\n",
        "\n",
        "    frequency_vec = []\n",
        "\n",
        "    for image_visual_words in visual_words:\n",
        "\n",
        "        # 200 represents the number of cluster centroids\n",
        "        image_frequency = np.zeros(200)\n",
        "\n",
        "        # val represents the index and this index refers to the vocabulary\n",
        "        for val in image_visual_words:\n",
        "\n",
        "            # image_frequency[val] will count the number of times that vocabulary appears within an image\n",
        "            # Shape = (200,)\n",
        "            image_frequency[val] += 1\n",
        "\n",
        "        frequency_vec.append(image_frequency)\n",
        "\n",
        "    return frequency_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3adef940",
      "metadata": {
        "id": "3adef940"
      },
      "outputs": [],
      "source": [
        "frequency_vec = histogram(visual_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7153890b",
      "metadata": {
        "id": "7153890b",
        "outputId": "34b1a3dc-82c1-4e31-fdfd-a205fa2f565e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1350\n",
            "<class 'list'>\n",
            "\n",
            "200\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(len(frequency_vec))\n",
        "print(type(frequency_vec))\n",
        "print()\n",
        "print(len(frequency_vec[0]))\n",
        "print(type(frequency_vec[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7a94960",
      "metadata": {
        "id": "c7a94960"
      },
      "source": [
        "## 3.3. Training Data to feed the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185caf32",
      "metadata": {
        "id": "185caf32"
      },
      "outputs": [],
      "source": [
        "train_data = np.stack(frequency_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60502fa3",
      "metadata": {
        "id": "60502fa3",
        "outputId": "3411aba9-5072-4aa4-af95-58bd7e0a9f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1350, 200)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape)\n",
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7d863d",
      "metadata": {
        "id": "9c7d863d"
      },
      "source": [
        "# 4. Using the functions to create feature vectors for the Validation set:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee9abf87",
      "metadata": {
        "id": "ee9abf87"
      },
      "source": [
        "## 4.1. Extracting Dense SIFT Features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d600d120",
      "metadata": {
        "id": "d600d120"
      },
      "outputs": [],
      "source": [
        "key_points_val, dense_descriptors_val = sift_features(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d54376c",
      "metadata": {
        "id": "0d54376c",
        "outputId": "11f6f7da-c664-4e62-91b9-ca5059e583ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n",
            "<class 'list'>\n",
            "1024\n",
            "<class 'tuple'>\n",
            "\n",
            "\n",
            "150\n",
            "<class 'list'>\n",
            "(1024, 128)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Key points\n",
        "print(len(key_points_val))\n",
        "print(type(key_points_val))\n",
        "print(len(key_points_val[0]))\n",
        "print(type(key_points_val[0]))\n",
        "print()\n",
        "print()\n",
        "\n",
        "# Descriptors\n",
        "print(len(dense_descriptors_val))\n",
        "print(type(dense_descriptors_val))\n",
        "print(dense_descriptors_val[0].shape)\n",
        "print(type(dense_descriptors_val[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13695587",
      "metadata": {
        "id": "13695587"
      },
      "source": [
        "## 4.2. Mapping the features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "943324ec",
      "metadata": {
        "id": "943324ec"
      },
      "outputs": [],
      "source": [
        "visual_words_val = mapping(dense_descriptors_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed19bd8",
      "metadata": {
        "id": "9ed19bd8",
        "outputId": "99b2e930-14f9-4aba-9cc3-545039661543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n",
            "<class 'list'>\n",
            "\n",
            "1024\n",
            "<class 'numpy.ndarray'>\n",
            "[ 34  34  34 ... 129 129 129]\n"
          ]
        }
      ],
      "source": [
        "# The variable visual_words represents the mapping to the vocabulary\n",
        "print(len(visual_words_val))\n",
        "print(type(visual_words_val))\n",
        "print()\n",
        "\n",
        "print(len(visual_words_val[0]))\n",
        "print(type(visual_words_val[0]))\n",
        "print(visual_words_val[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9378a858",
      "metadata": {
        "id": "9378a858"
      },
      "source": [
        "## 4.3. Creating the Histograms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b5e435",
      "metadata": {
        "id": "21b5e435"
      },
      "outputs": [],
      "source": [
        "# Validation data input\n",
        "frequency_vec_val = histogram(visual_words_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae96d08e",
      "metadata": {
        "id": "ae96d08e",
        "outputId": "225bc7b9-9430-4ff6-c574-7c2da593e4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n",
            "<class 'list'>\n",
            "\n",
            "200\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(len(frequency_vec_val))\n",
        "print(type(frequency_vec_val))\n",
        "print()\n",
        "print(len(frequency_vec_val[0]))\n",
        "print(type(frequency_vec_val[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b8199a",
      "metadata": {
        "id": "82b8199a"
      },
      "source": [
        "## 4.4. Validation Data to feed the Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92bc9f9",
      "metadata": {
        "id": "d92bc9f9"
      },
      "outputs": [],
      "source": [
        "val_data = np.stack(frequency_vec_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c5e693",
      "metadata": {
        "id": "69c5e693",
        "outputId": "b52c44ca-037a-4fe8-fcae-02a3000e0288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150, 200)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(val_data.shape)\n",
        "print(type(val_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2616c1b8",
      "metadata": {
        "id": "2616c1b8"
      },
      "source": [
        "# 5. Classification using SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18db627f",
      "metadata": {
        "id": "18db627f",
        "outputId": "3d3add4d-794c-4c95-c34e-bb401bdfa16f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(degree=8, kernel='poly')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training the SVM\n",
        "svc = SVC(kernel = \"poly\", degree = 8)\n",
        "svc.fit(train_data, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae1a435",
      "metadata": {
        "id": "fae1a435"
      },
      "outputs": [],
      "source": [
        "predictions = svc.predict(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f229494",
      "metadata": {
        "id": "4f229494",
        "outputId": "c60e0346-382b-4d2a-d69b-3c8197815779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80        12\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        10\n",
            "           3       1.00      0.40      0.57        10\n",
            "           4       0.92      0.60      0.73        20\n",
            "           5       0.50      0.17      0.25         6\n",
            "           6       0.00      0.00      0.00         8\n",
            "           7       0.00      0.00      0.00        11\n",
            "           8       1.00      0.25      0.40         8\n",
            "           9       0.08      1.00      0.14         8\n",
            "          10       1.00      0.09      0.17        11\n",
            "          11       1.00      0.27      0.43        11\n",
            "          12       0.00      0.00      0.00        12\n",
            "          13       0.25      0.12      0.17         8\n",
            "          14       0.25      0.11      0.15         9\n",
            "\n",
            "    accuracy                           0.27       150\n",
            "   macro avg       0.47      0.25      0.25       150\n",
            "weighted avg       0.52      0.27      0.30       150\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/ComputerVision/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/anaconda3/envs/ComputerVision/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/anaconda3/envs/ComputerVision/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_val, predictions))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}